{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuUlRV6So2FvuLrlLyS37F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaqanashraf/video-scraping/blob/master/video-scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_6tDabslhRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "# from pytube import YouTube\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfg00oKGmmIV",
        "colab_type": "code",
        "outputId": "3ae052d3-bfca-4a99-c0f0-230dd41e502c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFYaNlkP9klx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AccVzC7787J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the function scrap frames from an image\n",
        "def get_frames_from_video(video_path , delay):\n",
        "    \n",
        "    \"\"\"\n",
        "        video_path is the path to the video with video formate\n",
        "        e.g '/content/gdrive/My Drive/videos/video.mp4'\n",
        "\n",
        "\n",
        "        delay is the parameter to fetch a frame from video after a certain delay\n",
        "        like you want to fetch each frame after 5 seconds\n",
        "\n",
        "\n",
        "        it will return each frame fetched from the video given by video_path after \n",
        "        each delay given by 'delay' parameter in numpy\n",
        "    \n",
        "    \"\"\"\n",
        "        \n",
        "\n",
        "    \n",
        "    vidcap = cv2.VideoCapture(video_path)\n",
        "    success,image = vidcap.read()\n",
        "    count = 0\n",
        "    frames = list()\n",
        "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "    i = 0\n",
        "    while success: \n",
        "        frames.append(image)\n",
        "        success,image = vidcap.read()\n",
        "\n",
        "        print(f'Read a new frame{i}: ', success)\n",
        "        count += delay*fps\n",
        "        i+=1\n",
        "        vidcap.set(1, count)\n",
        "    return  np.array(frames)\n",
        "\n",
        "\n",
        "def scrap_faces_from_image(image, cascade_path):\n",
        "\n",
        "    \"\"\"\n",
        "          image: is the numpy multidimensional array having pixel values of images at location\n",
        "\n",
        "          cascade_path: it is a complete path to an xml document. \n",
        "          this xml document contains real values of pretrained model.\n",
        "          for scraping of faces we can use cascade_frontalface_default or any other varient.\n",
        "          the related pre trained values can be found at 'https://github.com/opencv/opencv/tree/master/data/haarcascades'\n",
        "\n",
        "          it will return boxes e.i coordinates of faces detected in the image\n",
        "          there could be more than one face\n",
        "          each face is coordinated with x,y,w,h (x and y are the left top corner of the box whereas 'w' is the width of the box and 'h' is the height of the box)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    face_cascade = cv2.CascadeClassifier(cascade_path)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "    return faces\n",
        "\n",
        "def crop_faces_from_image(faces, img):\n",
        "\n",
        "    \"\"\"\n",
        "          faces: is the numpy multidimensional array containing coordinates of each faces the image contained\n",
        "          each face box can be expressed as the following tuple (x,y,w,h)\n",
        "\n",
        "          img: is the image containing some faces\n",
        "\n",
        "\n",
        "          return: the function return a multidiemnsional numpy array containg cropped faces according to given coordinates in 'faces'\n",
        "    \"\"\"\n",
        "\n",
        "    face_images = list()\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "        face_image = img[y:y+h, x:x+w]\n",
        "        face_images.append(face_image)\n",
        "\n",
        "    return np.array(face_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLaDIEnUusvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the complete path where the video is located\n",
        "video_path = '/content/gdrive/My Drive/videos/pyare_afzal.mp4'\n",
        "# the directory where I want to save my scrapped faces images\n",
        "directory = '/content/gdrive/My Drive/videos/pyare_afzal'\n",
        "# complete path to where pretrained cascade xml file resides\n",
        "cascade_path = '/content/gdrive/My Drive/videos/haarcascade_frontalface_default.xml'\n",
        "# interval after which the frame would be fetched\n",
        "delay = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxEp1HtV0xTt",
        "colab_type": "code",
        "outputId": "7788cd68-48f1-4f31-827b-688769806986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "# getting all frames from the vide\n",
        "frames = get_frames_from_video(video_path, delay)\n",
        "frames.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read a new frame0:  True\n",
            "Read a new frame1:  True\n",
            "Read a new frame2:  True\n",
            "Read a new frame3:  True\n",
            "Read a new frame4:  True\n",
            "Read a new frame5:  True\n",
            "Read a new frame6:  True\n",
            "Read a new frame7:  True\n",
            "Read a new frame8:  True\n",
            "Read a new frame9:  True\n",
            "Read a new frame10:  True\n",
            "Read a new frame11:  True\n",
            "Read a new frame12:  True\n",
            "Read a new frame13:  True\n",
            "Read a new frame14:  True\n",
            "Read a new frame15:  True\n",
            "Read a new frame16:  True\n",
            "Read a new frame17:  True\n",
            "Read a new frame18:  True\n",
            "Read a new frame19:  True\n",
            "Read a new frame20:  True\n",
            "Read a new frame21:  True\n",
            "Read a new frame22:  True\n",
            "Read a new frame23:  True\n",
            "Read a new frame24:  True\n",
            "Read a new frame25:  True\n",
            "Read a new frame26:  True\n",
            "Read a new frame27:  True\n",
            "Read a new frame28:  True\n",
            "Read a new frame29:  True\n",
            "Read a new frame30:  True\n",
            "Read a new frame31:  True\n",
            "Read a new frame32:  True\n",
            "Read a new frame33:  True\n",
            "Read a new frame34:  True\n",
            "Read a new frame35:  True\n",
            "Read a new frame36:  True\n",
            "Read a new frame37:  True\n",
            "Read a new frame38:  True\n",
            "Read a new frame39:  False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 360, 450, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFbiW0Gl7ZVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "croped_faces = list()\n",
        "for frame in frames:\n",
        "    # find coordinates of faces contained by this frame\n",
        "    faces = scrap_faces_from_image(frame, cascade_path)\n",
        "    # slice the area of the frame where the face is by given coordinates\n",
        "    croped_faces.extend(crop_faces_from_image(faces, frame))\n",
        "\n",
        "croped_faces = np.array(croped_faces)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Flo6W0Wt79D9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "for face in croped_faces:\n",
        "    # convert faces to gray scale\n",
        "    gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "    # save these cropped gray scale face images to the directory in jpg format\n",
        "    cv2.imwrite(f'{directory}/face{i}.jpg', gray)\n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5M3Sm4b-Liv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}